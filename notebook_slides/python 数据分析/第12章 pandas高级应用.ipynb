{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb9060f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "前面的章节关注于不同类型的数据规整流程和NumPy、pandas与其它库的特点。随着时间的发展，pandas发展出了更多适合高级用户的功能。本章就要深入学习pandas的高级功能。\n",
    "\n",
    "# 12.1 分类数据\n",
    "\n",
    "这一节介绍的是pandas的分类类型。我会向你展示通过使用它，提高性能和内存的使用率。我还会介绍一些在统计和机器学习中使用分类数据的工具。\n",
    "\n",
    "## 背景和目的\n",
    "\n",
    "表中的一列通常会有重复的包含不同值的小集合的情况。我们已经学过了unique和value_counts，它们可以从数组提取出不同的值，并分别计算频率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [10]: import numpy as np; import pandas as pd\n",
    "\n",
    "In [11]: values = pd.Series(['apple', 'orange', 'apple',\n",
    "   ....:                     'apple'] * 2)\n",
    "\n",
    "In [12]: values\n",
    "Out[12]: \n",
    "0     apple\n",
    "1    orange\n",
    "2     apple\n",
    "3     apple\n",
    "4     apple\n",
    "5    orange\n",
    "6     apple\n",
    "7     apple\n",
    "dtype: object\n",
    "\n",
    "In [13]: pd.unique(values)\n",
    "Out[13]: array(['apple', 'orange'], dtype=object)\n",
    "\n",
    "In [14]: pd.value_counts(values)\n",
    "Out[14]: \n",
    "apple     6\n",
    "orange    2\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8eebe",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "许多数据系统（数据仓库、统计计算或其它应用）都发展出了特定的表征重复值的方法，以进行高效的存储和计算。在数据仓库中，最好的方法是使用所谓的包含不同值的维表(Dimension Table)，将主要的参数存储为引用维表整数键："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98816fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [15]: values = pd.Series([0, 1, 0, 0] * 2)\n",
    "\n",
    "In [16]: dim = pd.Series(['apple', 'orange'])\n",
    "\n",
    "In [17]: values\n",
    "Out[17]: \n",
    "0    0\n",
    "1    1\n",
    "2    0\n",
    "3    0\n",
    "4    0\n",
    "5    1\n",
    "6    0\n",
    "7    0\n",
    "dtype: int64\n",
    "\n",
    "In [18]: dim\n",
    "Out[18]: \n",
    "0     apple\n",
    "1    orange\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dbe653",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "可以使用take方法存储原始的字符串Series："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [19]: dim.take(values)\n",
    "Out[19]: \n",
    "0     apple\n",
    "1    orange\n",
    "0     apple\n",
    "0     apple\n",
    "0     apple\n",
    "1    orange\n",
    "0     apple\n",
    "0     apple\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74233b74",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "这种用整数表示的方法称为分类或字典编码表示法。不同值得数组称为分类、字典或数据级。本书中，我们使用分类的说法。表示分类的整数值称为分类编码或简单地称为编码。\n",
    "\n",
    "分类表示可以在进行分析时大大的提高性能。你也可以在保持编码不变的情况下，对分类进行转换。一些相对简单的转变例子包括：\n",
    "\n",
    "- 重命名分类。\n",
    "- 加入一个新的分类，不改变已经存在的分类的顺序或位置。\n",
    "\n",
    "## pandas的分类类型\n",
    "\n",
    "pandas有一个特殊的分类类型，用于保存使用整数分类表示法的数据。看一个之前的Series例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [20]: fruits = ['apple', 'orange', 'apple', 'apple'] * 2\n",
    "\n",
    "In [21]: N = len(fruits)\n",
    "\n",
    "In [22]: df = pd.DataFrame({'fruit': fruits,\n",
    "   ....:                    'basket_id': np.arange(N),\n",
    "   ....:                    'count': np.random.randint(3, 15, size=N),\n",
    "   ....:                    'weight': np.random.uniform(0, 4, size=N)},\n",
    "   ....:                   columns=['basket_id', 'fruit', 'count', 'weight'])\n",
    "\n",
    "In [23]: df\n",
    "Out[23]: \n",
    "   basket_id   fruit  count    weight\n",
    "0          0   apple      5  3.858058\n",
    "1          1  orange      8  2.612708\n",
    "2          2   apple      4  2.995627\n",
    "3          3   apple      7  2.614279\n",
    "4          4   apple     12  2.990859\n",
    "5          5  orange      8  3.845227\n",
    "6          6   apple      5  0.033553\n",
    "7          7   apple      4  0.425778"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1673b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "这里，df['fruit']是一个Python字符串对象的数组。我们可以通过调用它，将它转变为分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2236901",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [24]: fruit_cat = df['fruit'].astype('category')\n",
    "\n",
    "In [25]: fruit_cat\n",
    "Out[25]: \n",
    "0     apple\n",
    "1    orange\n",
    "2     apple\n",
    "3     apple\n",
    "4     apple\n",
    "5    orange\n",
    "6     apple\n",
    "7     apple\n",
    "Name: fruit, dtype: category\n",
    "Categories (2, object): [apple, orange]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13804bbc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "fruit_cat的值不是NumPy数组，而是一个pandas.Categorical实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [26]: c = fruit_cat.values\n",
    "\n",
    "In [27]: type(c)\n",
    "Out[27]: pandas.core.categorical.Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f854f66",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "分类对象有categories和codes属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6fae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [28]: c.categories\n",
    "Out[28]: Index(['apple', 'orange'], dtype='object')\n",
    "\n",
    "In [29]: c.codes\n",
    "Out[29]: array([0, 1, 0, 0, 0, 1, 0, 0], dtype=int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763b7b9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "你可将DataFrame的列通过分配转换结果，转换为分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd43e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [30]: df['fruit'] = df['fruit'].astype('category')\n",
    "\n",
    "In [31]: df.fruit\n",
    "Out[31]:\n",
    "0     apple\n",
    "1    orange\n",
    "2     apple\n",
    "3     apple\n",
    "4     apple\n",
    "5    orange\n",
    "6     apple\n",
    "7     apple\n",
    "Name: fruit, dtype: category\n",
    "Categories (2, object): [apple, orange]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5795eb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "你还可以从其它Python序列直接创建pandas.Categorical："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca175168",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [32]: my_categories = pd.Categorical(['foo', 'bar', 'baz', 'foo', 'bar'])\n",
    "\n",
    "In [33]: my_categories\n",
    "Out[33]: \n",
    "[foo, bar, baz, foo, bar]\n",
    "Categories (3, object): [bar, baz, foo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0d867",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "如果你已经从其它源获得了分类编码，你还可以使用from_codes构造器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49822a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [34]: categories = ['foo', 'bar', 'baz']\n",
    "\n",
    "In [35]: codes = [0, 1, 2, 0, 0, 1]\n",
    "\n",
    "In [36]: my_cats_2 = pd.Categorical.from_codes(codes, categories)\n",
    "\n",
    "In [37]: my_cats_2\n",
    "Out[37]: \n",
    "[foo, bar, baz, foo, foo, bar]\n",
    "Categories (3, object): [foo, bar, baz]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12d5db",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "与显示指定不同，分类变换不认定指定的分类顺序。因此取决于输入数据的顺序，categories数组的顺序会不同。当使用from_codes或其它的构造器时，你可以指定分类一个有意义的顺序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [38]: ordered_cat = pd.Categorical.from_codes(codes, categories,\n",
    "   ....:                                         ordered=True)\n",
    "\n",
    "In [39]: ordered_cat\n",
    "Out[39]: \n",
    "[foo, bar, baz, foo, foo, bar]\n",
    "Categories (3, object): [foo < bar < baz]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6999e6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "输出[foo < bar < baz]指明‘foo’位于‘bar’的前面，以此类推。无序的分类实例可以通过as_ordered排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9368ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [40]: my_cats_2.as_ordered()\n",
    "Out[40]: \n",
    "[foo, bar, baz, foo, foo, bar]\n",
    "Categories (3, object): [foo < bar < baz]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd87a383",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "最后要注意，分类数据不需要字符串，尽管我仅仅展示了字符串的例子。分类数组可以包括任意不可变类型。\n",
    "\n",
    "## 用分类进行计算\n",
    "\n",
    "与非编码版本（比如字符串数组）相比，使用pandas的Categorical有些类似。某些pandas组件，比如groupby函数，更适合进行分类。还有一些函数可以使用有序标志位。\n",
    "\n",
    "来看一些随机的数值数据，使用pandas.qcut面元函数。它会返回pandas.Categorical，我们之前使用过pandas.cut，但没解释分类是如何工作的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd53d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [41]: np.random.seed(12345)\n",
    "\n",
    "In [42]: draws = np.random.randn(1000)\n",
    "\n",
    "In [43]: draws[:5]\n",
    "Out[43]: array([-0.2047,  0.4789, -0.5194, -0.5557,  1.9658])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a03cd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "计算这个数据的分位面元，提取一些统计信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [44]: bins = pd.qcut(draws, 4)\n",
    "\n",
    "In [45]: bins\n",
    "Out[45]: \n",
    "[(-0.684, -0.0101], (-0.0101, 0.63], (-0.684, -0.0101], (-0.684, -0.0101], (0.63,\n",
    " 3.928], ..., (-0.0101, 0.63], (-0.684, -0.0101], (-2.95, -0.684], (-0.0101, 0.63\n",
    "], (0.63, 3.928]]\n",
    "Length: 1000\n",
    "Categories (4, interval[float64]): [(-2.95, -0.684] < (-0.684, -0.0101] < (-0.010\n",
    "1, 0.63] <\n",
    "                                    (0.63, 3.928]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2b7ea",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "虽然有用，确切的样本分位数与分位的名称相比，不利于生成汇总。我们可以使用labels参数qcut，实现目的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [46]: bins = pd.qcut(draws, 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "\n",
    "In [47]: bins\n",
    "Out[47]: \n",
    "[Q2, Q3, Q2, Q2, Q4, ..., Q3, Q2, Q1, Q3, Q4]\n",
    "Length: 1000\n",
    "Categories (4, object): [Q1 < Q2 < Q3 < Q4]\n",
    "\n",
    "In [48]: bins.codes[:10]\n",
    "Out[48]: array([1, 2, 1, 1, 3, 3, 2, 2, 3, 3], dtype=int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0fedb2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "加上标签的面元分类不包含数据面元边界的信息，因此可以使用groupby提取一些汇总信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ec347",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [49]: bins = pd.Series(bins, name='quartile')\n",
    "\n",
    "In [50]: results = (pd.Series(draws)\n",
    "   ....:            .groupby(bins)\n",
    "   ....:            .agg(['count', 'min', 'max'])\n",
    "   ....:            .reset_index())\n",
    "\n",
    "In [51]: results\n",
    "Out[51]: \n",
    "  quartile  count       min       max\n",
    "0       Q1    250 -2.949343 -0.685484\n",
    "1       Q2    250 -0.683066 -0.010115\n",
    "2       Q3    250 -0.010032  0.628894\n",
    "3       Q4    250  0.634238  3.927528"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f0ce87",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "分位数列保存了原始的面元分类信息，包括排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [52]: results['quartile']\n",
    "Out[52]:\n",
    "0    Q1\n",
    "1    Q2\n",
    "2    Q3\n",
    "3    Q4\n",
    "Name: quartile, dtype: category\n",
    "Categories (4, object): [Q1 < Q2 < Q3 < Q4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489316e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## 用分类提高性能\n",
    "\n",
    "如果你是在一个特定数据集上做大量分析，将其转换为分类可以极大地提高效率。DataFrame列的分类使用的内存通常少的多。来看一些包含一千万元素的Series，和一些不同的分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [53]: N = 10000000\n",
    "\n",
    "In [54]: draws = pd.Series(np.random.randn(N))\n",
    "\n",
    "In [55]: labels = pd.Series(['foo', 'bar', 'baz', 'qux'] * (N // 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad80ea",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "现在，将标签转换为分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [56]: categories = labels.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f37db8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "这时，可以看到标签使用的内存远比分类多："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [57]: labels.memory_usage()\n",
    "Out[57]: 80000080\n",
    "\n",
    "In [58]: categories.memory_usage()\n",
    "Out[58]: 10000272"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c930ad3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "转换为分类不是没有代价的，但这是一次性的代价："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ccbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [59]: %time _ = labels.astype('category')\n",
    "CPU times: user 490 ms, sys: 240 ms, total: 730 ms\n",
    "Wall time: 726 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1eb4e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "GroupBy使用分类操作明显更快，是因为底层的算法使用整数编码数组，而不是字符串数组。\n",
    "\n",
    "## 分类方法\n",
    "\n",
    "包含分类数据的Series有一些特殊的方法，类似于Series.str字符串方法。它还提供了方便的分类和编码的使用方法。看下面的Series："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7cc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [60]: s = pd.Series(['a', 'b', 'c', 'd'] * 2)\n",
    "\n",
    "In [61]: cat_s = s.astype('category')\n",
    "\n",
    "In [62]: cat_s\n",
    "Out[62]: \n",
    "0    a\n",
    "1    b\n",
    "2    c\n",
    "3    d\n",
    "4    a\n",
    "5    b\n",
    "6    c\n",
    "7    d\n",
    "dtype: category\n",
    "Categories (4, object): [a, b, c, d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584db0c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "特别的cat属性提供了分类方法的入口："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059fb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [63]: cat_s.cat.codes\n",
    "Out[63]: \n",
    "0    0\n",
    "1    1\n",
    "2    2\n",
    "3    3\n",
    "4    0\n",
    "5    1\n",
    "6    2\n",
    "7    3\n",
    "dtype: int8\n",
    "\n",
    "In [64]: cat_s.cat.categories\n",
    "Out[64]: Index(['a', 'b', 'c', 'd'], dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e407af7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "假设我们知道这个数据的实际分类集，超出了数据中的四个值。我们可以使用set_categories方法改变它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54701a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [65]: actual_categories = ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "In [66]: cat_s2 = cat_s.cat.set_categories(actual_categories)\n",
    "\n",
    "In [67]: cat_s2\n",
    "Out[67]: \n",
    "0    a\n",
    "1    b\n",
    "2    c\n",
    "3    d\n",
    "4    a\n",
    "5    b\n",
    "6    c\n",
    "7    d\n",
    "dtype: category\n",
    "Categories (5, object): [a, b, c, d, e]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0d92a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "虽然数据看起来没变，新的分类将反映在它们的操作中。例如，如果有的话，value_counts表示分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [68]: cat_s.value_counts()\n",
    "Out[68]: \n",
    "d    2\n",
    "c    2\n",
    "b    2\n",
    "a    2\n",
    "dtype: int64\n",
    "\n",
    "In [69]: cat_s2.value_counts()\n",
    "Out[69]: \n",
    "d    2\n",
    "c    2\n",
    "b    2\n",
    "a    2\n",
    "e    0\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa47157",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "在大数据集中，分类经常作为节省内存和高性能的便捷工具。过滤完大DataFrame或Series之后，许多分类可能不会出现在数据中。我们可以使用remove_unused_categories方法删除没看到的分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [70]: cat_s3 = cat_s[cat_s.isin(['a', 'b'])]\n",
    "\n",
    "In [71]: cat_s3\n",
    "Out[71]: \n",
    "0    a\n",
    "1    b\n",
    "4    a\n",
    "5    b\n",
    "dtype: category\n",
    "Categories (4, object): [a, b, c, d]\n",
    "\n",
    "In [72]: cat_s3.cat.remove_unused_categories()\n",
    "Out[72]: \n",
    "0    a\n",
    "1    b\n",
    "4    a\n",
    "5    b\n",
    "dtype: category\n",
    "Categories (2, object): [a, b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad81895",
   "metadata": {},
   "source": [
    "表12-1列出了可用的分类方法。\n",
    "\n",
    "![表12-1 pandas的Series的分类方法](http://upload-images.jianshu.io/upload_images/7178691-6c602152c2bba658.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8fab8f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## 为建模创建虚拟变量\n",
    "\n",
    "当你使用统计或机器学习工具时，通常会将分类数据转换为虚拟变量，也称为one-hot编码。这包括创建一个不同类别的列的DataFrame；这些列包含给定分类的1s，其它为0。\n",
    "\n",
    "看前面的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa78e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [73]: cat_s = pd.Series(['a', 'b', 'c', 'd'] * 2, dtype='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29780f4c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "前面的第7章提到过，pandas.get_dummies函数可以转换这个分类数据为包含虚拟变量的DataFrame："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd360e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [74]: pd.get_dummies(cat_s)\n",
    "Out[74]: \n",
    "   a  b  c  d\n",
    "0  1  0  0  0\n",
    "1  0  1  0  0\n",
    "2  0  0  1  0\n",
    "3  0  0  0  1\n",
    "4  1  0  0  0\n",
    "5  0  1  0  0\n",
    "6  0  0  1  0\n",
    "7  0  0  0  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d87ab6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 12.2 GroupBy高级应用\n",
    "\n",
    "尽管我们在第10章已经深度学习了Series和DataFrame的Groupby方法，还有一些方法也是很有用的。\n",
    "\n",
    "## 分组转换和“解封”GroupBy\n",
    "\n",
    "在第10章，我们在分组操作中学习了apply方法，进行转换。还有另一个transform方法，它与apply很像，但是对使用的函数有一定限制：\n",
    "\n",
    "- 它可以产生向分组形状广播标量值\n",
    "- 它可以产生一个和输入组形状相同的对象\n",
    "- 它不能修改输入\n",
    "\n",
    "来看一个简单的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [75]: df = pd.DataFrame({'key': ['a', 'b', 'c'] * 4,\n",
    "   ....:                    'value': np.arange(12.)})\n",
    "\n",
    "In [76]: df\n",
    "Out[76]: \n",
    "   key  value\n",
    "0    a    0.0\n",
    "1    b    1.0\n",
    "2    c    2.0\n",
    "3    a    3.0\n",
    "4    b    4.0\n",
    "5    c    5.0\n",
    "6    a    6.0\n",
    "7    b    7.0\n",
    "8    c    8.0\n",
    "9    a    9.0\n",
    "10   b   10.0\n",
    "11   c   11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db5b53",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "按键进行分组："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [77]: g = df.groupby('key').value\n",
    "\n",
    "In [78]: g.mean()\n",
    "Out[78]: \n",
    "key\n",
    "a    4.5\n",
    "b    5.5\n",
    "c    6.5\n",
    "Name: value, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcea21",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "假设我们想产生一个和df['value']形状相同的Series，但值替换为按键分组的平均值。我们可以传递函数lambda x: x.mean()进行转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [79]: g.transform(lambda x: x.mean())\n",
    "Out[79]: \n",
    "0     4.5\n",
    "1     5.5\n",
    "2     6.5\n",
    "3     4.5\n",
    "4     5.5\n",
    "5     6.5\n",
    "6     4.5\n",
    "7     5.5\n",
    "8     6.5\n",
    "9     4.5\n",
    "10    5.5\n",
    "11    6.5\n",
    "Name: value, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e71ee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "对于内置的聚合函数，我们可以传递一个字符串假名作为GroupBy的agg方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [80]: g.transform('mean')\n",
    "Out[80]: \n",
    "0     4.5\n",
    "1     5.5\n",
    "2     6.5\n",
    "3     4.5\n",
    "4     5.5\n",
    "5     6.5\n",
    "6     4.5\n",
    "7     5.5\n",
    "8     6.5\n",
    "9     4.5\n",
    "10    5.5\n",
    "11    6.5\n",
    "Name: value, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353d9da",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "与apply类似，transform的函数会返回Series，但是结果必须与输入大小相同。举个例子，我们可以用lambda函数将每个分组乘以2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1333d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [81]: g.transform(lambda x: x * 2)\n",
    "Out[81]: \n",
    "0      0.0\n",
    "1      2.0\n",
    "2      4.0\n",
    "3      6.0\n",
    "4      8.0\n",
    "5     10.0\n",
    "6     12.0\n",
    "7     14.0\n",
    "8     16.0\n",
    "9     18.0\n",
    "10    20.0\n",
    "11    22.0\n",
    "Name: value, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6298c22",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "再举一个复杂的例子，我们可以计算每个分组的降序排名："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [82]: g.transform(lambda x: x.rank(ascending=False))\n",
    "Out[82]: \n",
    "0     4.0\n",
    "1     4.0\n",
    "2     4.0\n",
    "3     3.0\n",
    "4     3.0\n",
    "5     3.0\n",
    "6     2.0\n",
    "7     2.0\n",
    "8     2.0\n",
    "9     1.0\n",
    "10    1.0\n",
    "11    1.0\n",
    "Name: value, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59b2e9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "看一个由简单聚合构造的的分组转换函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3197960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966478b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "我们用transform或apply可以获得等价的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [84]: g.transform(normalize)\n",
    "Out[84]: \n",
    "0    -1.161895\n",
    "1    -1.161895\n",
    "2    -1.161895\n",
    "3    -0.387298\n",
    "4    -0.387298\n",
    "5    -0.387298\n",
    "6     0.387298\n",
    "7     0.387298\n",
    "8     0.387298\n",
    "9     1.161895\n",
    "10    1.161895\n",
    "11    1.161895\n",
    "Name: value, dtype: float64\n",
    "\n",
    "In [85]: g.apply(normalize)\n",
    "Out[85]: \n",
    "0    -1.161895\n",
    "1    -1.161895\n",
    "2    -1.161895\n",
    "3    -0.387298\n",
    "4    -0.387298\n",
    "5    -0.387298\n",
    "6     0.387298\n",
    "7     0.387298\n",
    "8     0.387298\n",
    "9     1.161895\n",
    "10    1.161895\n",
    "11    1.161895\n",
    "Name: value, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff1186",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "内置的聚合函数，比如mean或sum，通常比apply函数快，也比transform快。这允许我们进行一个所谓的解封（unwrapped）分组操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d5730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [86]: g.transform('mean')\n",
    "Out[86]: \n",
    "0     4.5\n",
    "1     5.5\n",
    "2     6.5\n",
    "3     4.5\n",
    "4     5.5\n",
    "5     6.5\n",
    "6     4.5\n",
    "7     5.5\n",
    "8     6.5\n",
    "9     4.5\n",
    "10    5.5\n",
    "11    6.5\n",
    "Name: value, dtype: float64\n",
    "\n",
    "In [87]: normalized = (df['value'] - g.transform('mean')) / g.transform('std')\n",
    "\n",
    "In [88]: normalized\n",
    "Out[88]: \n",
    "0    -1.161895\n",
    "1    -1.161895\n",
    "2    -1.161895\n",
    "3    -0.387298\n",
    "4    -0.387298\n",
    "5    -0.387298\n",
    "6     0.387298\n",
    "7     0.387298\n",
    "8     0.387298\n",
    "9     1.161895\n",
    "10    1.161895\n",
    "11    1.161895\n",
    "Name: value, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb153f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "解封分组操作可能包括多个分组聚合，但是矢量化操作还是会带来收益。\n",
    "\n",
    "## 分组的时间重采样\n",
    "\n",
    "对于时间序列数据，resample方法从语义上是一个基于内在时间的分组操作。下面是一个示例表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c742546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [89]: N = 15\n",
    "\n",
    "In [90]: times = pd.date_range('2017-05-20 00:00', freq='1min', periods=N)\n",
    "\n",
    "In [91]: df = pd.DataFrame({'time': times,\n",
    "   ....:                    'value': np.arange(N)})\n",
    "\n",
    "In [92]: df\n",
    "Out[92]: \n",
    "                  time  value\n",
    "0  2017-05-20 00:00:00      0\n",
    "1  2017-05-20 00:01:00      1\n",
    "2  2017-05-20 00:02:00      2\n",
    "3  2017-05-20 00:03:00      3\n",
    "4  2017-05-20 00:04:00      4\n",
    "5  2017-05-20 00:05:00      5\n",
    "6  2017-05-20 00:06:00      6\n",
    "7  2017-05-20 00:07:00      7\n",
    "8  2017-05-20 00:08:00      8\n",
    "9  2017-05-20 00:09:00      9\n",
    "10 2017-05-20 00:10:00     10\n",
    "11 2017-05-20 00:11:00     11\n",
    "12 2017-05-20 00:12:00     12\n",
    "13 2017-05-20 00:13:00     13\n",
    "14 2017-05-20 00:14:00     14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21103c6a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "这里，我们可以用time作为索引，然后重采样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85327895",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [93]: df.set_index('time').resample('5min').count()\n",
    "Out[93]: \n",
    "                     value\n",
    "time                      \n",
    "2017-05-20 00:00:00      5\n",
    "2017-05-20 00:05:00      5\n",
    "2017-05-20 00:10:00      5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0107de",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "假设DataFrame包含多个时间序列，用一个额外的分组键的列进行标记："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162119cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [94]: df2 = pd.DataFrame({'time': times.repeat(3),\n",
    "   ....:                     'key': np.tile(['a', 'b', 'c'], N),\n",
    "   ....:                     'value': np.arange(N * 3.)})\n",
    "\n",
    "In [95]: df2[:7]\n",
    "Out[95]: \n",
    "  key                time  value\n",
    "0   a 2017-05-20 00:00:00    0.0\n",
    "1   b 2017-05-20 00:00:00    1.0\n",
    "2   c 2017-05-20 00:00:00    2.0\n",
    "3   a 2017-05-20 00:01:00    3.0\n",
    "4   b 2017-05-20 00:01:00    4.0\n",
    "5   c 2017-05-20 00:01:00    5.0\n",
    "6   a 2017-05-20 00:02:00    6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738593d2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "要对每个key值进行相同的重采样，我们引入pandas.TimeGrouper对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [96]: time_key = pd.TimeGrouper('5min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4effbfb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "我们然后设定时间索引，用key和time_key分组，然后聚合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [97]: resampled = (df2.set_index('time')\n",
    "   ....:              .groupby(['key', time_key])\n",
    "   ....:              .sum())\n",
    "\n",
    "In [98]: resampled\n",
    "Out[98]: \n",
    "                         value\n",
    "key time                      \n",
    "a   2017-05-20 00:00:00   30.0\n",
    "    2017-05-20 00:05:00  105.0\n",
    "    2017-05-20 00:10:00  180.0\n",
    "b   2017-05-20 00:00:00   35.0\n",
    "    2017-05-20 00:05:00  110.0\n",
    "    2017-05-20 00:10:00  185.0\n",
    "c   2017-05-20 00:00:00   40.0\n",
    "    2017-05-20 00:05:00  115.0\n",
    "    2017-05-20 00:10:00  190.0\n",
    "\n",
    "In [99]: resampled.reset_index()\n",
    "Out[99]:\n",
    "key                time  value\n",
    "0   a 2017-05-20 00:00:00   30.0\n",
    "1   a 2017-05-20 00:05:00  105.0\n",
    "2   a 2017-05-20 00:10:00  180.0\n",
    "3   b 2017-05-20 00:00:00   35.0\n",
    "4   b 2017-05-20 00:05:00  110.0\n",
    "5   b 2017-05-20 00:10:00  185.0\n",
    "6   c 2017-05-20 00:00:00   40.0\n",
    "7   c 2017-05-20 00:05:00  115.0\n",
    "8   c 2017-05-20 00:10:00  190.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a025f8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "使用TimeGrouper的限制是时间必须是Series或DataFrame的索引。\n",
    "\n",
    "# 12.3 链式编程技术\n",
    "\n",
    "当对数据集进行一系列变换时，你可能发现创建的多个临时变量其实并没有在分析中用到。看下面的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df2 = df[df['col2'] < 0]\n",
    "df2['col1_demeaned'] = df2['col1'] - df2['col1'].mean()\n",
    "result = df2.groupby('key').col1_demeaned.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d503878",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "虽然这里没有使用真实的数据，这个例子却指出了一些新方法。首先，DataFrame.assign方法是一个df[k] = v形式的函数式的列分配方法。它不是就地修改对象，而是返回新的修改过的DataFrame。因此，下面的语句是等价的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a420e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual non-functional way\n",
    "df2 = df.copy()\n",
    "df2['k'] = v\n",
    "\n",
    "# Functional assign way\n",
    "df2 = df.assign(k=v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280905cf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "就地分配可能会比assign快，但是assign可以方便地进行链式编程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (df2.assign(col1_demeaned=df2.col1 - df2.col2.mean())\n",
    "          .groupby('key')\n",
    "          .col1_demeaned.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637b507",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "我使用外括号，这样便于添加换行符。\n",
    "\n",
    "使用链式编程时要注意，你可能会需要涉及临时对象。在前面的例子中，我们不能使用load_data的结果，直到它被赋值给临时变量df。为了这么做，assign和许多其它pandas函数可以接收类似函数的参数，即可调用对象（callable）。为了展示可调用对象，看一个前面例子的片段："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df2 = df[df['col2'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af290173",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "它可以重写为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32519932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (load_data()\n",
    "      [lambda x: x['col2'] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304a6f5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "这里，load_data的结果没有赋值给某个变量，因此传递到[ ]的函数在这一步被绑定到了对象。\n",
    "\n",
    "我们可以把整个过程写为一个单链表达式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9986f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (load_data()\n",
    "          [lambda x: x.col2 < 0]\n",
    "          .assign(col1_demeaned=lambda x: x.col1 - x.col1.mean())\n",
    "          .groupby('key')\n",
    "          .col1_demeaned.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2884cce",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "是否将代码写成这种形式只是习惯而已，将它分开成若干步可以提高可读性。\n",
    "\n",
    "## 管道方法\n",
    "\n",
    "你可以用Python内置的pandas函数和方法，用带有可调用对象的链式编程做许多工作。但是，有时你需要使用自己的函数，或是第三方库的函数。这时就要用到管道方法。\n",
    "\n",
    "看下面的函数调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ff35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f(df, arg1=v1)\n",
    "b = g(a, v2, arg3=v3)\n",
    "c = h(b, arg4=v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c656a2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "当使用接收、返回Series或DataFrame对象的函数式，你可以调用pipe将其重写："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (df.pipe(f, arg1=v1)\n",
    "          .pipe(g, v2, arg3=v3)\n",
    "          .pipe(h, arg4=v4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec29f9d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "f(df)和df.pipe(f)是等价的，但是pipe使得链式声明更容易。\n",
    "\n",
    "pipe的另一个有用的地方是提炼操作为可复用的函数。看一个从列减去分组方法的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ee18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby(['key1', 'key2'])\n",
    "df['col1'] = df['col1'] - g.transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fee2dc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "假设你想转换多列，并修改分组的键。另外，你想用链式编程做这个转换。下面就是一个方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_demean(df, by, cols):\n",
    "    result = df.copy()\n",
    "    g = df.groupby(by)\n",
    "    for c in cols:\n",
    "        result[c] = df[c] - g[c].transform('mean')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d54f84",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "然后可以写为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (df[df.col1 < 0]\n",
    "          .pipe(group_demean, ['key1', 'key2'], ['col1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72c338",
   "metadata": {},
   "source": [
    "# 12.4 总结\n",
    "\n",
    "和其它许多开源项目一样，pandas仍然在不断的变化和进步中。和本书中其它地方一样，这里的重点是放在接下来几年不会发生什么改变且稳定的功能。\n",
    "\n",
    "为了深入学习pandas的知识，我建议你学习官方文档，并阅读开发团队发布的文档更新。我们还邀请你加入pandas的开发工作：修改bug、创建新功能、完善文档。"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
