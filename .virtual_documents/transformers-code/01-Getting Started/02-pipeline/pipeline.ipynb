


from transformers.pipelines import SUPPORTED_TASKS


print(SUPPORTED_TASKS.items())


for k, v in SUPPORTED_TASKS.items():
    print(k, v)





from transformers import pipeline





pipe = pipeline("text-classification")


pipe(["very good!", "vary bad!"])





# https://huggingface.co/models
pipe = pipeline("text-classification", model="uer/roberta-base-finetuned-dianping-chinese")


pipe("我觉得不太行！")





# 这种方式，必须同时指定model和tokenizer
model = AutoModelForSequenceClassification.from_pretrained("uer/roberta-base-finetuned-dianping-chinese")
tokenizer = AutoTokenizer.from_pretrained("uer/roberta-base-finetuned-dianping-chinese")
pipe = pipeline("text-classification", model=model, tokenizer=tokenizer)


pipe("我觉得不太行！")


pipe.model.device


import torch
import time
times = []
for i in range(100):
    torch.cuda.synchronize()
    start = time.time()
    pipe("我觉得不太行！")
    torch.cuda.synchronize()
    end = time.time()
    times.append(end - start)
print(sum(times) / 100)





pipe = pipeline("text-classification", model="uer/roberta-base-finetuned-dianping-chinese", device=0)


pipe.model.device


import torch
import time
times = []
for i in range(100):
    torch.cuda.synchronize()
    start = time.time()
    pipe("我觉得不太行！")
    torch.cuda.synchronize()
    end = time.time()
    times.append(end - start)
print(sum(times) / 100)





qa_pipe = pipeline("question-answering", model="uer/roberta-base-chinese-extractive-qa")


qa_pipe


QuestionAnsweringPipeline 


qa_pipe(question="中国的首都是哪里？", context="中国的首都是北京", max_answer_len=1)





checkpoint = "google/owlvit-base-patch32"
detector = pipeline(model=checkpoint, task="zero-shot-object-detection")


import requests
from PIL import Image

url = "https://unsplash.com/photos/oj0zeY2Ltk4/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8MTR8fHBpY25pY3xlbnwwfHx8fDE2Nzc0OTE1NDk&force=true&w=640"
im = Image.open(requests.get(url, stream=True).raw)
im


predictions = detector(
    im,
    candidate_labels=["hat", "sunglasses", "book"],
)
predictions


from PIL import ImageDraw

draw = ImageDraw.Draw(im)

for prediction in predictions:
    box = prediction["box"]
    label = prediction["label"]
    score = prediction["score"]
    xmin, ymin, xmax, ymax = box.values()
    draw.rectangle((xmin, ymin, xmax, ymax), outline="red", width=1)
    draw.text((xmin, ymin), f"{label}: {round(score,2)}", fill="red")

im





from transformers import *
import torch


tokenizer = AutoTokenizer.from_pretrained("uer/roberta-base-finetuned-dianping-chinese")
model = AutoModelForSequenceClassification.from_pretrained("uer/roberta-base-finetuned-dianping-chinese")


input_text = "我觉得不太行！"
inputs = tokenizer(input_text, return_tensors="pt")
inputs


res = model(**inputs)
res


logits = res.logits
logits = torch.softmax(logits, dim=-1)
logits


pred = torch.argmax(logits).item()
pred


model.config.id2label


result = model.config.id2label.get(pred)
result



